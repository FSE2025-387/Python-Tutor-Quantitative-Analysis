{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bad6c0d",
   "metadata": {},
   "source": [
    "# Data management (individual QDPX project $\\to$ CSV files)\n",
    "\n",
    "STAGE 1 OF THE DATA PIPELINE\n",
    "\n",
    "Take an Atlas.ti project and extract the annotations into a longform CSV file (plus auxiliary info in other CSV files).\n",
    "\n",
    "Things that happen in this script:\n",
    "1. Walk XML trees in the QDPX project and generate corresponding rectangular dataframes\n",
    "2. Combine `Codebook` (code info) and `Sources` (document + annotation info) into a single dataframe\n",
    "3. Translate each \"guid\" into the human-readable interpretation (e.g., code or document name)\n",
    "4. Filter out (document, annotator) pairs not listed as \"completed\" in the Google spreadsheet\n",
    "5. Extract full quote text from chat transcripts (those stored in the XML file are truncated to a certain number of characters)\n",
    "6. In cases where the annotator failed to highlight full lines of text, fill out quotes using the chat transcript\n",
    "7. Extract the speaker identity from the quote text (as a nonnegative integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db29a0",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99df095",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = True\n",
    "\n",
    "input_version = 4   # 2, 3, or 4 (different versions have different documents)\n",
    "input_release = 1   # this increments with updates to the data\n",
    "output_version = 16\n",
    "\n",
    "descriptions = False # True for v2, False for v3 and v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd42402",
   "metadata": {},
   "source": [
    "## Baseline setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ET.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "qdpxdir = \"full-project-data-{}.{}\".format(input_version, input_release)\n",
    "inputdocsdir = \"sources\"\n",
    "qdefile = \"project.qde\"\n",
    "\n",
    "document_metadata_file = os.path.join(datadir, \"annotation-timeline.csv\")\n",
    "\n",
    "outputparentdir = \"../output\"\n",
    "outputchilddir = \"v{}\".format(output_version)\n",
    "outputdir = os.path.join(outputparentdir, outputchilddir)\n",
    "\n",
    "# stage 1\n",
    "usersfile = \"users.csv\"\n",
    "codesfile = \"codes.csv\"\n",
    "sourcesfile = \"raw-masked-annotations.csv\"\n",
    "samplesourcesfile = \"small-\" + sourcesfile\n",
    "notesfile = \"notes.csv\"\n",
    "linksfile = \"links.csv\"\n",
    "setsfile = \"sets.csv\"\n",
    "\n",
    "# stage 2\n",
    "speakererrorsfile = \"ambiguous-speaker-quotations.txt\"\n",
    "annotationsfile = \"human-readable-annotations.csv\"\n",
    "sampleannotationsfile = \"small-\" + annotationsfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    try:\n",
    "        os.mkdir(outputparentdir)\n",
    "    except FileExistsError:\n",
    "        print(\"High-level output directory already exists; no action taken.\")\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(outputdir)\n",
    "    except FileExistsError:\n",
    "        print(\"WARNING: low-level output directory already exists. You might want to increment your version number.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbaf5f",
   "metadata": {},
   "source": [
    "## Read in the raw data\n",
    "We'll read the whole file into a big tree structure, then take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20006805",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = os.path.join(datadir, qdpxdir, qdefile)\n",
    "tree = ET.parse(fin)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce75b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root:\n",
    "    print(child.tag, \"\\n\\t\", child.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab9481",
   "metadata": {},
   "source": [
    "### 0. Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bfb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Users\n",
    "for user in root[0]: # \"User\"\n",
    "    print(\"User\", user.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ae35b",
   "metadata": {},
   "source": [
    "### 1. Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a972b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Codebook > Codes\n",
    "# there are 70 of these - we'll only look at the first 3\n",
    "# root[1] is the CodeBook node\n",
    "# root[1][0] is its only child node - the Codes node - and its own children are Code nodes\n",
    "# root[1][0][0] is a Code node - access its name/label using `root[1][0][0].attrib[\"name\"]\n",
    "for code in root[1][0][0:3]: # \"Code\"\n",
    "    print(\"Code\", code.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in root[1][0][4]: # \"Code\"\n",
    "    print(\"Sub-Code\", code.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in root[1][0][4][0]: # \"Code\"\n",
    "    print(\"Sub-Sub-Code\", code.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9f7d1a",
   "metadata": {},
   "source": [
    "### 2. Sources (annotated documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f68dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing \"only the Sources (annotated documents)\" would give a lot of\n",
    "# output, so instead I'm only doing the first 3 quotes of the first\n",
    "# document\n",
    "\n",
    "print(\"NOTE: These aren't the real XML tags! They were too long.\\n\")\n",
    "\n",
    "doc = root[2][0] # \"TextSource\"\n",
    "print(\"Doc\", doc.attrib, \"\\n\")\n",
    "for quote in doc[0:3]: # \"PlaintextSelection\"\n",
    "    print(\"\\tQuote\", quote.attrib)\n",
    "    for code in quote: # \"Coding\"\n",
    "        print(\"\\t\\tCode\", code.attrib)\n",
    "        for ref in code: # \"CodeRef\"\n",
    "            print(\"\\t\\t\\tCodeRef\", ref.attrib)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc84295",
   "metadata": {},
   "source": [
    "### 3. Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6087982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Notes (the first 3)\n",
    "for note in root[3][0:3]: # \"Notes\"\n",
    "    print(\"Note\", note.attrib, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b67859",
   "metadata": {},
   "source": [
    "### 4. Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Links\n",
    "if not input_version in {4}:\n",
    "    for link in root[4]: # \"Link\"\n",
    "        print(\"Link\", link.attrib, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc306fe",
   "metadata": {},
   "source": [
    "### 5. Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b60e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Sets\n",
    "if not input_version in {4}:\n",
    "    for codeSet in root[5]: # \"Set\"\n",
    "        print(\"Set\", codeSet.attrib)\n",
    "        for code in codeSet[0:min(len(codeSet), 3)]: # \"MemberCode\"\n",
    "            print(\"\\tMemberCode\", code.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fcf899",
   "metadata": {},
   "source": [
    "## Create raw dataframes (sometimes within directories)\n",
    "Here, we must split the big XML file into subtrees before reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f8f1a",
   "metadata": {},
   "source": [
    "### 0. Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name\n",
    "usersStr = ET.tostring(root[0], encoding='utf8', method='xml')\n",
    "\n",
    "usersDa = pd.read_xml(usersStr)\n",
    "\n",
    "usersDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccc805",
   "metadata": {},
   "source": [
    "### 1. Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root[1][0][3][0].attrib # FIXME forgot that the codebook is nested now FML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_description(node):\n",
    "    if node.tag == \"{urn:QDA-XML:project:1.0}Description\":\n",
    "        assert(len(node) == 0 and len(node.attrib) == 0)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd064bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leaf(node):\n",
    "    if len(node) == 0:\n",
    "        return True\n",
    "    if len(node) == 1 and is_description(node[0]):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa5a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codebookDepth = 0\n",
    "codebookSize = 0 # only leaf nodes\n",
    "bfsq = [(root[1][0], 0)]\n",
    "curDepth = 1\n",
    "\n",
    "while len(bfsq) > 0:\n",
    "    # debugging\n",
    "    prevDepth = curDepth\n",
    "    \n",
    "    # regular stuff\n",
    "    curNode, curDepth = bfsq.pop(0)\n",
    "    \n",
    "    # debugging\n",
    "    if prevDepth != curDepth and curDepth > 0:\n",
    "        print(\"\\n\\n{}.\".format(curDepth), end = \" \")\n",
    "    try:\n",
    "        print(curNode.attrib[\"name\"], end = \"     \")\n",
    "    except(KeyError):\n",
    "        print(\"FIXME (Node type: {}; Attributes: {})\".format(curNode.tag.split(\"}\")[1], curNode.attrib), end = \"     \")\n",
    "    \n",
    "    # remove Description nodes, as they're annoying\n",
    "    if is_description(curNode):\n",
    "        continue\n",
    "    \n",
    "    # regular stuff\n",
    "    codebookDepth = curDepth\n",
    "    if is_leaf(curNode):\n",
    "        codebookSize += 1\n",
    "    for child in curNode:\n",
    "        bfsq.append((child, curDepth+1))\n",
    "    \n",
    "    # debugging\n",
    "    #if not \"name\" in curNode.attrib.keys():\n",
    "    #    print(curNode.tag, end=\", \")\n",
    "    #    print(curNode.attrib)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Codebook depth: {}\".format(codebookDepth))\n",
    "print(\"Number of interesting leaf nodes: {}\".format(codebookSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ae557",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookCols = [\"guid\", \"color\", \"isCodable\", \"name\"] + [\"lvl_{}\".format(k+1) for k in range(codebookDepth)]\n",
    "print(codebookCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookArr = [None] * codebookSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_field(node, field):\n",
    "    try:\n",
    "        return node.attrib[field]\n",
    "    except(KeyError):\n",
    "        if node.tag == \"{urn:QDA-XML:project:1.0}Codes\":\n",
    "            return \"*\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = []\n",
    "idx = 0\n",
    "\n",
    "# pre-order dfs\n",
    "def dfs(cur, idx):\n",
    "    if not is_description(cur):\n",
    "        # leaf node\n",
    "        if is_leaf(cur):\n",
    "            # debugging\n",
    "            #print(\"{}. \".format(idx) + \" > \".join([get_node_field(node, \"name\") for node in trace]))\n",
    "            names = [get_node_field(node, \"name\") for node in trace]\n",
    "            row = [get_node_field(cur, col) for col in codebookCols[:3]] + [\" > \".join(names)] + names\n",
    "            codebookArr[idx] = row\n",
    "            idx += 1\n",
    "        # internal node\n",
    "        else:\n",
    "            for child in cur:\n",
    "                trace.append(child)\n",
    "                idx = dfs(child, idx)\n",
    "    trace.pop(len(trace) - 1)\n",
    "    return idx\n",
    "\n",
    "for node in root[1][0]:\n",
    "    trace.append(node)\n",
    "    idx = dfs(node, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daed2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookArr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3349f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDa = pd.DataFrame(data = codebookArr, columns = codebookCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7834c2d",
   "metadata": {},
   "source": [
    "### 2. Sources (annotated documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b838f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name, creatingUser, creationDateTime, plainTextPath, richTextPath\n",
    "sourcesStr = ET.tostring(root[2], encoding='utf8', method='xml')\n",
    "\n",
    "sourcesDa = pd.read_xml(sourcesStr)\n",
    "\n",
    "assert(sourcesDa[\"PlainTextSelection\"].dropna().shape[0] == 0)\n",
    "sourcesDa = sourcesDa.drop(\"PlainTextSelection\", axis=1)\n",
    "\n",
    "sourcesDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ed259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sourcesDa[\"Description\"].value_counts() # just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources are deeply nested compared to the other stuff. This directory will look like:\n",
    "# sourcesDir = {Doc guid > (quotesDa, quotesDir)} where for each Doc,\n",
    "# quotesDir = {Quote guid > codesDa} where for each Quote, codeRefs have been pivoted\n",
    "#                                    into codesDa (I think there's only one per code)\n",
    "sourcesDir = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d227946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    print(root[2][0][k].attrib[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quote\n",
    "quote = root[2][0][0]\n",
    "print(quote.tag)\n",
    "quote.attrib # Atlas didn't wanna store the text I guess UPDATE - Atlas has changed its mind, see cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ann in enumerate(quote):\n",
    "    print(idx, \":\", ann)\n",
    "    print(ann.attrib)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adebc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an annotation (coding)\n",
    "ann = quote[0]\n",
    "print(ann.tag)\n",
    "ann.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a30e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a code reference\n",
    "ref = ann[0]\n",
    "print(ref.tag)\n",
    "ref.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6005f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "idx : index of the document (order of upload to Atlas)\n",
    "\"\"\"\n",
    "def get_doc_text(idx):\n",
    "    fin = sourcesDa.at[idx, \"plainTextPath\"].split(\"//\")[1]\n",
    "    #print(fin)\n",
    "    fin = os.path.join(datadir, qdpxdir, inputdocsdir, fin)\n",
    "    #print(fin)\n",
    "\n",
    "    f = open(fin)\n",
    "\n",
    "    # source document as a string\n",
    "    docstr = f.read()\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return docstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quote.attrib\n",
    "\"targetGUID\" in code.attrib.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd995ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDa[codebookDa[\"lvl_2\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858b750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cols of these: guid, name, creatingUser, creationDateTime, startPosition, endPosition\n",
    "c = 0\n",
    "for doc_idx, doc in enumerate(root[2]):\n",
    "    # print(doc.attrib[\"name\"])\n",
    "    quotesStr = ET.tostring(doc, encoding='utf8', method='xml')\n",
    "    \n",
    "    try:\n",
    "        quotesDa = pd.read_xml(quotesStr)\n",
    "        try:\n",
    "            assert(quotesDa[\"Coding\"].dropna().shape[0] == 0) # should be able to do this with len() instead\n",
    "            quotesDa = quotesDa.drop(\"Coding\", axis=1)\n",
    "        except(KeyError):\n",
    "            print(\"WARNING: Document {} has no Coding's.\\n\".format(doc.attrib[\"name\"]))\n",
    "    \n",
    "    except(ValueError):\n",
    "        # document hasn't been annotated\n",
    "        sourcesDa.drop(sourcesDa.index[sourcesDa[\"guid\"] == doc.attrib[\"guid\"]], inplace=True)\n",
    "        continue\n",
    "    \n",
    "    # remove rows that are just Descriptions\n",
    "    if \"Description\" in quotesDa.columns:\n",
    "        print(\"Description found -- File: {}, GUID: {}\".format(doc.attrib[\"name\"], doc.attrib[\"name\"]))\n",
    "        assert(doc.attrib[\"guid\"] == \"B889885D-0073-4C1F-B748-106B7C01FD10\") # THIS MAY CHANGE\n",
    "        quotesDa = quotesDa[quotesDa[\"Description\"].isna()].drop(columns=[\"Description\"])\n",
    "        #display(quotesDa)\n",
    "    \n",
    "    quotesDir = {}\n",
    "    \n",
    "    for quote in doc:\n",
    "        if c < 3:\n",
    "            print(\"quote: {}\".format(quote.attrib[\"guid\"]))\n",
    "            c += 1\n",
    "        codesStr = ET.tostring(quote, encoding='utf8', method='xml')\n",
    "        try:\n",
    "            codesDa = pd.read_xml(codesStr)\n",
    "        except(ValueError):\n",
    "            # Sometimes we delete a coding but the orphaned quotation\n",
    "            # stays in the file. This is uninteresting so we skip it.\n",
    "            if \"guid\" in quote.attrib.keys():\n",
    "                quotesDa = quotesDa.loc[quotesDa[\"guid\"] != quote.attrib[\"guid\"]].reset_index(drop=True)\n",
    "            continue\n",
    "        \n",
    "        # initialize derived columns to store information in XML child nodes\n",
    "        codesDa[\"isCode\"] = False\n",
    "        codesDa[\"isNote\"] = False\n",
    "        codesDa[\"CodeRef.targetGUID\"] = np.nan\n",
    "        codesDa[\"NoteRef.targetGUID\"] = np.nan\n",
    "        \n",
    "        # upward reference to the quote that all these codes were assigned to\n",
    "        codesDa[\"quoteGUID\"] = quote.attrib[\"guid\"]\n",
    "        \n",
    "        # code- and note-specific actions\n",
    "        for idx, coding in enumerate(quote): # \"Coding\"\n",
    "            if len(coding) == 1:\n",
    "                code = coding[0]\n",
    "            else:\n",
    "                print(\"WARNING: Coding {} has {} Refs\".format(coding.tag, len(coding)))\n",
    "                print(code.attrib)\n",
    "                1/0\n",
    "            \n",
    "            if code.tag == \"{urn:QDA-XML:project:1.0}CodeRef\":\n",
    "                codesDa.at[idx, \"isCode\"] = True\n",
    "                if \"targetGUID\" in code.attrib:\n",
    "                    codesDa.at[idx, \"CodeRef.targetGUID\"] = code.attrib[\"targetGUID\"]\n",
    "                else:\n",
    "                    # debugging\n",
    "                    warning = \"WARNING: Document {} > Quote \\\"{}\\\" > Code \\\"{}\\\" has {} references\\n\".format(\n",
    "                        doc.attrib[\"name\"], \n",
    "                        quote.attrib[\"name\"], \n",
    "                        code.attrib, \n",
    "                        len(code))\n",
    "                    print(warning)\n",
    "            elif code.tag == \"{urn:QDA-XML:project:1.0}NoteRef\":\n",
    "                codesDa.at[idx, \"isNote\"] = True\n",
    "                codesDa.at[idx, \"NoteRef.targetGUID\"] = code.attrib[\"targetGUID\"]\n",
    "            else:\n",
    "                # debugging\n",
    "                warning = \"WARNING: unrecognized XML tag in Document {} > Quote {} > {} {}\\n\".format(\n",
    "                    doc.attrib[\"name\"], \n",
    "                    quote.attrib[\"name\"], \n",
    "                    code.tag, \n",
    "                    code.attrib)\n",
    "                print(warning)\n",
    "        \n",
    "        # default-initialize any columns we need for merging later\n",
    "        tagset = {coding[0].tag for coding in quote}\n",
    "        \n",
    "        if not \"{urn:QDA-XML:project:1.0}CodeRef\" in tagset:\n",
    "            codesDa[\"guid\"] = np.nan\n",
    "            codesDa[\"creatingUser\"] = np.nan\n",
    "            codesDa[\"creationDateTime\"] = np.nan\n",
    "        if not \"{urn:QDA-XML:project:1.0}NoteRef\" in tagset:\n",
    "            codesDa[\"targetGUID\"] = np.nan\n",
    "        else:\n",
    "            print(\"Document {} > quote {} has notes\".format(doc.attrib[\"name\"], quote.attrib[\"name\"]))\n",
    "        \n",
    "        # write output\n",
    "        quotesDir[quote.attrib[\"guid\"]] = codesDa\n",
    "\n",
    "    # write more output\n",
    "    sourcesDir[doc.attrib[\"guid\"]] = (quotesDa, quotesDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only runs correctly for Project Version 2/3 (I hardcoded the index for testing)\n",
    "quotesDa = sourcesDir[\"E266595E-8846-4BB3-904F-A818FDD5DC0B\"][0]\n",
    "display(quotesDa[quotesDa[\"guid\"] == \"D087E98C-3500-429E-A6A0-43EB9388E7B1\"])\n",
    "display(quotesDa[quotesDa[\"guid\"] == \"B4E46844-CBFA-431C-BCFD-3EB82155E6CA\"])\n",
    "display(quotesDa[quotesDa[\"guid\"] == \"799E4C5D-76F8-4CFA-A438-BE8A1B92157B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7183d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotesDa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "codesDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa38b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "code.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd27944",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f42e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0\n",
    "q = 1\n",
    "(sourcesDir[list(sourcesDir.keys())[d]][q])[list(sourcesDir[list(sourcesDir.keys())[d]][q].keys())[2]]\n",
    "#len(sourcesDir[list(sourcesDir.keys())[d]][q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f04aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcesDa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79b75a",
   "metadata": {},
   "source": [
    "See the first dataframe below for a \"standard\" `quotesDa` (all elements are either `Coding`s or `NoteRef`s).\n",
    "\n",
    "See the second dataframe below for a \"standard\" `codesDa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check I did it right\n",
    "#display(sourcesDir[\"378A15D0-C2D3-4E73-AC3E-DC9B260BD9D4\"][0].head(3)) # quotesDa\n",
    "#display(sourcesDir[\"378A15D0-C2D3-4E73-AC3E-DC9B260BD9D4\"][1][\"49EB5814-CAAE-43DD-B03D-E77B98C7753C\"]) # codesDa\n",
    "src = list(sourcesDir.keys())[0]\n",
    "display(sourcesDir[src][0].head(3))\n",
    "display(sourcesDir[src][1][list(sourcesDir[src][1].keys())[0]]) # codesDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5192869",
   "metadata": {},
   "source": [
    "### 3. Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name, creatingUser, creationDateTime, modifyingUser, modifiedDateTime, plainTextPath, richTextPath\n",
    "notesStr = ET.tostring(root[3], encoding='utf8', method='xml')\n",
    "\n",
    "notesDa = pd.read_xml(notesStr)\n",
    "\n",
    "notesDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a2c53",
   "metadata": {},
   "source": [
    "### 4. Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255937ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name, color, direction, originGUID, targetGUID\n",
    "if not input_version in {4}:\n",
    "    linksStr = ET.tostring(root[4], encoding='utf8', method='xml')\n",
    "\n",
    "    linksDa = pd.read_xml(linksStr)\n",
    "\n",
    "    display(linksDa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5ce36",
   "metadata": {},
   "source": [
    "### 5. Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28711447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: name, guid\n",
    "if not input_version in {4}:\n",
    "    setsStr = ET.tostring(root[5], encoding='utf8', method='xml')\n",
    "\n",
    "    setsDa = pd.read_xml(setsStr)\n",
    "\n",
    "    memberTypes = list(setsDa.columns)[2:]\n",
    "\n",
    "    for memberType in memberTypes:\n",
    "        newColName = memberType + \".targetGUIDs\"\n",
    "        setsDa.rename(columns={memberType : newColName}, inplace=True)\n",
    "        setsDa[newColName] = \"N/A\"\n",
    "\n",
    "    display(setsDa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2269b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not input_version in {4}:\n",
    "    for idx, codeSet in enumerate(root[5]):\n",
    "        members = {member.tag : [] for member in codeSet}\n",
    "        for member in codeSet:\n",
    "            members[member.tag].append(member.attrib[\"targetGUID\"])\n",
    "        #print(members, \"\\n\")\n",
    "        for tag, targetGUIDs in members.items():\n",
    "            col = tag.split('}')[1] + \".targetGUIDs\"\n",
    "            setsDa.at[idx, col] = targetGUIDs\n",
    "\n",
    "    display(setsDa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519db55",
   "metadata": {},
   "source": [
    "## Now that we have all the data out of XML, we need to consolidate it\n",
    "Specifically, No. 2: Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91830ae6",
   "metadata": {},
   "source": [
    "### 2. Sources\n",
    "We want to merge all the different dictionaries and dataframes into a single dataframe of annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relevant data structures (for now) are sourcesDa and sourcesDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcesDir = doc guid -> (quotesDa, quotesDir)\n",
    "# quotesDa = quote guid x [text, start, end, time, doc, etc.]\n",
    "# quotesDir = quote guid -> codesDa\n",
    "# codesDa = code/noteref x [code vs note flag, note target guid, quote guid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c729b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reminding myself what they look like...\n",
    "src_guid_ex = sourcesDa[\"guid\"][0]\n",
    "quotesDa_ex = sourcesDir[src_guid_ex][0]\n",
    "quotesDir_ex = sourcesDir[src_guid_ex][1]\n",
    "quote_guid_ex = list(quotesDir_ex.keys())[0]\n",
    "codesDa_ex = quotesDir_ex[quote_guid_ex]\n",
    "\n",
    "display(\"sources\", sourcesDa.head(3)) # documentsDa\n",
    "display(\"quotes\", quotesDa_ex.head(3)) # quotesDa\n",
    "display(\"annotations\", codesDa_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"22BDC312-CA2D-47C3-ABF8-453195276C54\" in sourcesDa[\"guid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c804aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"22BDC312-CA2D-47C3-ABF8-453195276C54\" in quotesDa_ex[\"guid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01daeeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"22BDC312-CA2D-47C3-ABF8-453195276C54\" in codesDa_ex[\"targetGUID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotesDa_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d967550",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quotesDir_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: why do I have a CodeRef column and both {}.targetGUID columns, but\n",
    "# no NoteRef column? Need to check whether Notes were taken at all\n",
    "for key, val in quotesDir_ex.items():\n",
    "    display(val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6c54b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for doc, (quotesDa, quotesDir) in sourcesDir.items():\n",
    "    #display(quotesDa)\n",
    "    for quote, codesDa in quotesDir.items():\n",
    "        count += 1\n",
    "        #print(quote)\n",
    "        #display(codesDa)\n",
    "    print(\"Finished document {} (total {} quotes)\".format(doc, count))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d072514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"B889885D-0073-4C1F-B748-106B7C01FD10\" in sourcesDir.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c655354",
   "metadata": {},
   "outputs": [],
   "source": [
    "docDir = {}\n",
    "\n",
    "for doc, (quotesDa, quotesDir) in sourcesDir.items():\n",
    "    #da = None\n",
    "    #for quote, codesDa in quotesDir.items():\n",
    "    #    tmpDa = codesDa.set_index(\"guid\")\n",
    "    #    if da is None:\n",
    "    #        da = tmpDa\n",
    "    #    else:\n",
    "    #        da = da.append(tmpDa)\n",
    "    #print(doc)\n",
    "    codesDa = pd.concat(quotesDir.values(), ignore_index=True)\n",
    "    docDir[doc] = codesDa.add_prefix(\"annotation.\").merge(quotesDa.add_prefix(\"quote.\"), \n",
    "                                left_on=\"annotation.quoteGUID\", \n",
    "                                right_on=\"quote.guid\", \n",
    "                                suffixes=(\"__ERROR-left\", \"__ERROR-right\"), \n",
    "                                how=\"outer\")\n",
    "    docDir[doc][\"quote.documentGUID\"] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(docDir[src_guid_ex].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233dd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.concat(docDir.values(), ignore_index=True).astype({\"quote.startPosition\": \"int64\", \n",
    "                                                           \"quote.endPosition\": \"int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c90c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if descriptions:\n",
    "    display(sourcesDa[sourcesDa[\"Description\"].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if descriptions:\n",
    "    display(sourcesDa[\"Description\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.merge(sourcesDa.add_prefix(\"document.\"), \n",
    "              left_on=\"quote.documentGUID\", \n",
    "              right_on=\"document.guid\", \n",
    "              suffixes=(\"__ERROR-left\", \"__ERROR-right\"), \n",
    "              how=\"outer\")\n",
    "da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"annotation.isCode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538011cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"annotation.isNote\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065324f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da.head(5))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(da[\"annotation.CodeRef\"].value_counts()) == 0) # remove this in the next cell\n",
    "display(da[\"annotation.isCode\"].value_counts()) # FIXME check that the mechanism I'm using to decide this is still valid\n",
    "assert(len(da[\"annotation.targetGUID\"].value_counts()) == 0) # remove this in the next cell\n",
    "\n",
    "# these are fine, just rare\n",
    "if descriptions:\n",
    "    #display(da[\"quote.Description\"].value_counts()) # FIXME this makes input version 5 break\n",
    "    display(da[\"document.Description\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.drop(columns=[\"annotation.CodeRef\", \"annotation.targetGUID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from annotation.CodeRef.guid\n",
    "codebookDa[codebookDa[\"guid\"] == \"AE184BD2-6DF4-492B-B4FE-F7D446C30B51\"] # yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7d567",
   "metadata": {},
   "source": [
    "### Output sources and all the other data as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92417afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    usersDa.to_csv(os.path.join(outputdir, usersfile))\n",
    "    codebookDa.to_csv(os.path.join(outputdir, codesfile))\n",
    "    da.to_csv(os.path.join(outputdir, sourcesfile))\n",
    "    da.head(20).to_csv(os.path.join(outputdir, samplesourcesfile)) # for easy visualization on GitHub\n",
    "    notesDa.to_csv(os.path.join(outputdir, notesfile))\n",
    "    if not input_version in {4}:\n",
    "        linksDa.to_csv(os.path.join(outputdir, linksfile))\n",
    "        setsDa.to_csv(os.path.join(outputdir, setsfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b72fd",
   "metadata": {},
   "source": [
    "## Consolidate even more\n",
    "\n",
    "Instead of 5 dataframes, we want 1 (or $<$5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094fc1c",
   "metadata": {},
   "source": [
    "### Drop value-less columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91734dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = []\n",
    "for col in da.columns:\n",
    "    #print(col, \":\", len(da[col].unique()))\n",
    "    if len(da[col].unique()) == 1:\n",
    "        dropcols = dropcols + [col]\n",
    "print(dropcols)\n",
    "da1 = da.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv_cols = {#\"annotation.quoteGUID\" : \"quote.guid\", \n",
    "              #\"annotation.targetGUID\" : \"annotation.NoteRef.targetGUID\", \n",
    "              \"quote.documentGUID\" : \"document.guid\"}\n",
    "\n",
    "for left, right in equiv_cols.items():\n",
    "    if (da1[left].eq(da1[right]) | (da1[left].isna() & da1[right].isna())).all():\n",
    "        da1.drop(columns=left, inplace=True)\n",
    "    else:\n",
    "        print(\"oops, {} doesn't always equal {}\".format(left, right))\n",
    "        display(da1[da1[left].ne(da1[right])][left].value_counts())\n",
    "        display(da1[da1[left].ne(da1[right])][right].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b94f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\"annotation.creatingUser\" : \"annotation.creatingUserGUID\", \n",
    "          \"quote.creatingUser\" : \"quote.creatingUserGUID\", \n",
    "          \"quote.modifyingUser\" : \"quote.modifyingUserGUID\", \n",
    "          \"document.creatingUser\" : \"document.creatingUserGUID\"}\n",
    "da1.rename(columns=rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870418fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da1.head(5))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfe411",
   "metadata": {},
   "source": [
    "### Translate GUIDs into words, where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af389cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_identifier(guid, df, guid_col, id_col, id_type):\n",
    "    rows = df[df[guid_col] == guid].reset_index()\n",
    "    if len(rows) != 1:\n",
    "        #if guid is np.nan or guid is None:\n",
    "        if pd.isnull(guid):\n",
    "            return np.nan\n",
    "        err = \"ERROR query for {} guid {} produced {} results with the following identifier(s): \\n\\t{}\".format(\n",
    "            id_type, guid, len(rows), \"\\n\\t\".join(rows[id_col]))\n",
    "        raise Exception(err)\n",
    "    return rows.at[0, id_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb740e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guid_to_identifier(\"57500D78-CB6B-4955-9A3C-4A3940F6263A\", usersDa, \"guid\", \"name\", \"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE this code block is *supposed* to produce an error\n",
    "print(guid_to_identifier(\"fake-guid\", usersDa, \"guid\", \"name\", \"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_user(guid):\n",
    "    return guid_to_identifier(guid, usersDa, \"guid\", \"name\", \"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80111a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_code(guid):\n",
    "    return guid_to_identifier(guid, codebookDa, \"guid\", \"name\", \"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_note(guid):\n",
    "    return guid_to_identifier(guid, notesDa, \"guid\", \"name\", \"note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b44df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test them each once\n",
    "print(guid_to_user(\"8F219B13-6EC7-4DBD-A8B7-73F4C1A66B69\"))\n",
    "print(guid_to_code(\"AE184BD2-6DF4-492B-B4FE-F7D446C30B51\"))\n",
    "#print(guid_to_note(\"F3ACD375-0E92-4324-BE15-727C4651C1EE\")) # not using notes anymore apparently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for display purposes - to visualize the columns with GUID values\n",
    "cols = [\"annotation.creationDateTime\", \n",
    "        #\"annotation.isCode\", # got rid of these cause we only have Codes now(?)\n",
    "        #\"annotation.isNote\", \n",
    "        \"quote.name\", # not sure why this started causing errors all of a sudden\n",
    "        \"quote.creationDateTime\",\n",
    "        \"quote.startPosition\", \n",
    "        \"quote.endPosition\", \n",
    "        \"quote.modifiedDateTime\", \n",
    "        \"document.name\", \n",
    "        \"document.creationDateTime\", \n",
    "        \"document.plainTextPath\", \n",
    "        \"document.richTextPath\"]\n",
    "display(da1.drop(columns=[col for col in cols if col in da1.columns]).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(da1[\"annotation.NoteRef.targetGUID\"].value_counts(), \"\\n\")\n",
    "print(da1[\"quote.modifyingUserGUID\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b18689",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b064ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what's going on\n",
    "#da1[da1[\"annotation.creatingUserGUID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the user-based ones\n",
    "da1[\"annotation.creatingUser\"] = da1[[\"annotation.creatingUserGUID\"]].applymap(guid_to_user)[\"annotation.creatingUserGUID\"]\n",
    "da1[\"quote.creatingUser\"] = da1[[\"quote.creatingUserGUID\"]].applymap(guid_to_user)[\"quote.creatingUserGUID\"]\n",
    "da1[\"quote.modifyingUser\"] = da1[[\"quote.modifyingUserGUID\"]].applymap(guid_to_user)[\"quote.modifyingUserGUID\"]\n",
    "if not input_version in {4}:\n",
    "    da1[\"document.creatingUser\"] = da1[[\"document.creatingUserGUID\"]].applymap(guid_to_user)[\"document.creatingUserGUID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da1.head(3))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(da1[\"annotation.creatingUser\"].value_counts(), \"\\n\") # cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd517411",
   "metadata": {},
   "source": [
    "#### Annotations (Codes and Notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1[da1[\"annotation.CodeRef.targetGUID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the code-based ones\n",
    "da1[\"annotation.CodeRef.target\"] = da1[[\"annotation.CodeRef.targetGUID\"]].applymap(guid_to_code)[\"annotation.CodeRef.targetGUID\"]\n",
    "da1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c853198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the note-based ones (there's only one)\n",
    "#da1[\"annotation.NoteRef.target\"] = da1[[\"annotation.NoteRef.targetGUID\"]].applymap(guid_to_note)[\"annotation.NoteRef.targetGUID\"]\n",
    "#da1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a87628",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"quote.name\", \n",
    "        \"annotation.isCode\", \n",
    "        \"annotation.isNote\", \n",
    "        \"annotation.CodeRef.target\", \n",
    "        \"annotation.NoteRef.target\", \n",
    "        \"annotation.creatingUser\", \n",
    "        \"annotation.creationDateTime\", \n",
    "        \"quote.startPosition\", \n",
    "        \"quote.endPosition\", \n",
    "        \"quote.creatingUser\", \n",
    "        \"quote.creationDateTime\", \n",
    "        \"quote.modifyingUser\", \n",
    "        \"quote.modifiedDateTime\", \n",
    "        \"document.name\", \n",
    "        \"document.creatingUser\", \n",
    "        \"document.creationDateTime\", \n",
    "        \"document.modifyingUser\",\n",
    "        \"document.modifiedDateTime\", \n",
    "        \"document.plainTextPath\", \n",
    "        \"document.richTextPath\", \n",
    "        \"annotation.guid\", \n",
    "        \"annotation.CodeRef.targetGUID\", \n",
    "        \"quote.guid\", \n",
    "        \"document.guid\"]\n",
    "\n",
    "da2 = da1.copy()\n",
    "da2 = da2[[col for col in cols if col in da2.columns]]\n",
    "\n",
    "rename = {\"quote.name\" : \"quote.text\",\n",
    "          \"annotation.CodeRef.target\" : \"annotation.code\", \n",
    "          #\"annotation.NoteRef.target\" : \"annotation.note\", \n",
    "          \"annotation.CodeRef.targetGUID\" : \"annotation.codeRef.guid\"}\n",
    "\n",
    "da2.rename(columns=rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f482314",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da2.head(3))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5d52c",
   "metadata": {},
   "source": [
    "### Throw out document-annotator pairs not marked as part of the intentional dataset\n",
    "This removes documents that are incomplete, annotated under different schemes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfeb7e",
   "metadata": {},
   "source": [
    "From now on, we only work with data from documents whose annotations are complete according to the spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(da2[da2[\"document.name\"].str.endswith(\".txt\")].shape)\n",
    "# print(da2[~da2[\"document.name\"].str.endswith(\".txt\")].shape)\n",
    "# da3 = da2[da2[\"document.name\"].str.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96641d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotators = [\"P\", \"A\", \"W\"] # anonymized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78036fe",
   "metadata": {},
   "source": [
    "Read in the metadata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de680b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_metadata = pd.read_csv(document_metadata_file)\n",
    "document_metadata = document_metadata.set_index(\"Document Name\")\n",
    "document_metadata = document_metadata.drop(index=\"108\", columns=[\"Unnamed: 10\", \"Unnamed: 11\"])\n",
    "document_metadata = document_metadata.fillna({\"Notes\" : \"\"})\n",
    "document_metadata = document_metadata.fillna({annotator : False for annotator in annotators})\n",
    "\n",
    "document_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f123f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_metadata[\"W\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd05ad",
   "metadata": {},
   "source": [
    "From now on, we only work with data from documents whose annotations are complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound but incomplete filtering\n",
    "da3 = da2[da2[\"document.name\"].isin(document_metadata.index.unique())]\n",
    "da3 = da3.reset_index(drop=True)\n",
    "print(\"{} to {}\".format(da2.shape, da3.shape))\n",
    "da3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from the dataframe\n",
    "du = pd.Series(list(zip(da3[\"document.name\"], \n",
    "                        da3[\"annotation.creatingUser\"].str.split(\" \").str[0])), # first names only\n",
    "               index = da3.index)\n",
    "\n",
    "# read from the metadata\n",
    "completed = np.concatenate([list(zip(document_metadata.index[document_metadata[annotator]], \n",
    "                                    itertools.repeat(annotator))) \n",
    "                           for annotator in annotators], axis=0)\n",
    "\n",
    "# stupid numpy autoconvert thing\n",
    "completed = completed.T\n",
    "completed = list(zip(completed[0], completed[1]))\n",
    "#print(len(completed))\n",
    "\n",
    "fil = du.isin(completed)\n",
    "#print(fil.value_counts())\n",
    "\n",
    "print(da3.shape)\n",
    "da3 = da3[fil]\n",
    "print(da3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0667dd4",
   "metadata": {},
   "source": [
    "### Get more text from the original documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9777a2",
   "metadata": {},
   "source": [
    "Read in all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "doctext = {}\n",
    "docs = da3[\"document.plainTextPath\"].unique()\n",
    "docfnames = pd.Series(docs).str.split(\"//\").str[1]\n",
    "\n",
    "for i, doc in enumerate(docfnames):\n",
    "    #print(doc)\n",
    "    fin = os.path.join(datadir, qdpxdir, inputdocsdir, doc)\n",
    "    f = open(fin)\n",
    "    doctext[docs[i]] = f.read() # source document as a string\n",
    "    f.close()\n",
    "\n",
    "print(len(doctext), len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b1a82",
   "metadata": {},
   "source": [
    "Force the `quote.text` column to contain the entire quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_info = pd.Series(zip(da3[\"document.plainTextPath\"], da3[\"quote.startPosition\"], da3[\"quote.endPosition\"]), index=da3.index)\n",
    "quote_text = quote_info.map(lambda v, doctext=doctext : doctext[v[0]][v[1]:v[2]])\n",
    "da3[\"quote.text\"] = quote_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8a343",
   "metadata": {},
   "source": [
    "Extract the speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parstart = quote_info.map(lambda v, doctext=doctext : doctext[v[0]].rfind(\"\\n\", 0, v[1]) + 1)\n",
    "parstart = quote_info.map(lambda v, doctext=doctext : doctext[v[0]].rfind(\"\\n2019-\", 0, v[1]+5) + 1)\n",
    "(parstart == da3[\"quote.startPosition\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parend = quote_info.map(lambda v, doctext=doctext : doctext[v[0]].find(\"\\n\", v[2]))\n",
    "(parend == da3[\"quote.endPosition\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_info = pd.Series(zip(da3[\"document.plainTextPath\"], parstart, parend), index=da3.index)\n",
    "par_text = par_info.map(lambda v, doctext=doctext : doctext[v[0]][v[1]:v[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be8d2f",
   "metadata": {},
   "source": [
    "Debug the speaker scraping step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ee40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064a341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for items that don't have a speaker (usually they're code)\n",
    "err = \"**** MISSING SPEAKERS ****\\n\\n\"\n",
    "fil = ~par_text.str.lower().str.contains(\" person \")\n",
    "tmp = par_text[fil]\n",
    "for i in tmp.index:\n",
    "    err += \"[{}] {}:{}, {}, {}, {}\\n\".format(i, parstart[i], parend[i], \n",
    "                                             da3.loc[i, \"document.name\"], \n",
    "                                             da3.loc[i, \"annotation.creatingUser\"], \n",
    "                                             da3.loc[i, \"annotation.code\"])\n",
    "    err += tmp[i] + \"\\n\\n\"\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for items that don't have a speaker at the right index (results from the previous check are excluded)\n",
    "# this is now redundant to the next cell\n",
    "fil = ~fil & ~(par_text.str[24:32].str.lower() == \" person \")\n",
    "fil &= ~(par_text.str[24:46].str.lower() == \" code change : person \")\n",
    "fil &= ~(par_text.str[24:48].str.lower() == \" executed code : person \")\n",
    "tmp = par_text[fil]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for items that have multiple speakers (we don't exclude the previous ones here, as there are few)\n",
    "#fil = ~fil & (par_text.str.find(\"2019-\") != par_text.str.rfind(\"2019-\"))\n",
    "fil = par_text.str.find(\"2019-\") != par_text.str.rfind(\"2019-\")\n",
    "tmp = par_text[fil]\n",
    "print(len(tmp), \"items checked\")\n",
    "problems = {}\n",
    "for j in tmp.index: # this could be done more concisely using re, but I don't feel like scrolling all the way up to load the package\n",
    "    s = tmp[j]\n",
    "    i = 0\n",
    "    speakers = {}\n",
    "    while i != -1:\n",
    "        k, l = None, None\n",
    "        if s[i+24 : i+32].lower() == \" person \":\n",
    "            k = i + 32\n",
    "            l = s.find(\":\", i+32)\n",
    "            line = s[l+1:s.find(\"\\n\", l+1)].strip()\n",
    "            if line == \"(hello)\" or line == \"(bye)\":\n",
    "                k, l = None, None # skip these lines\n",
    "        elif s[i+24 : i+45].lower() == \" code change : person \":\n",
    "            k = i+45\n",
    "            l = s.find(\"\\n\", i+45)\n",
    "        elif s[i+24 : i+48].lower() == \" executed code : person \":\n",
    "            k = i+47\n",
    "            l = s.find(\"#########\", i+47)\n",
    "        else:\n",
    "            #print(\"~[{}] {}:{}, {}, {}, {}\".format(j, parstart[j], parend[j], \n",
    "            #                                      da3.loc[j, \"document.name\"], \n",
    "            #                                      da3.loc[j, \"annotation.creatingUser\"], \n",
    "            #                                      da3.loc[j, \"annotation.code\"]))\n",
    "            #print(s[i:], \"\\n\")\n",
    "            problems[(da3.loc[j, \"document.name\"], da3.loc[j, \"quote.startPosition\"], \n",
    "                      da3.loc[j, \"quote.endPosition\"])] = (da3.loc[j, \"document.plainTextPath\"], \n",
    "                                                           parstart[j], parend[j], speakers.copy())\n",
    "        \n",
    "        if k is not None and l is not None and k < l < len(s) and s[k:l].strip().isdigit():\n",
    "            key = s[k:l].strip()\n",
    "            if key in speakers.keys():\n",
    "                speakers[key] += 1\n",
    "            else:\n",
    "                speakers[key] = 1 # this is where the person ID is\n",
    "        \n",
    "        i = s.find(\"2019-\", i+33)\n",
    "    if len(speakers) != 1:\n",
    "        #print(\"[{}] {}:{}, {}, {}, {}\".format(j, parstart[j], parend[j], \n",
    "        #                                      da3.loc[j, \"document.name\"], \n",
    "        #                                      da3.loc[j, \"annotation.creatingUser\"], \n",
    "        #                                      da3.loc[j, \"annotation.code\"]))\n",
    "        #print(speakers)\n",
    "        #print(s, \"\\n\")\n",
    "        problems[(da3.loc[j, \"document.name\"], da3.loc[j, \"quote.startPosition\"], \n",
    "                  da3.loc[j, \"quote.endPosition\"])] = (da3.loc[j, \"document.plainTextPath\"], \n",
    "                                                       parstart[j], parend[j], speakers.copy())\n",
    "    #else:\n",
    "    #    print(\"[{}] ok\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6830a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(problems), \"problem quotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "err += \"\\n**** MULTIPLE SPEAKERS ****\\n\\n\"\n",
    "for i, ((doc, qstart, qstop), (path, pstart, pstop, speakers)) in enumerate(problems.items()):\n",
    "    err += \"{}) Document {} [{}:{}], speaker counts = {}\".format(i, doc, qstart, qstop, speakers) + \"\\n\"\n",
    "    err += doctext[path][qstart:qstop] + \"\\n\\n\"\n",
    "    if (qstart, qstop) != (pstart, pstop):\n",
    "        err += \"**context**\\n\"\n",
    "        err += doctext[path][pstart:pstop] + \"\\n\\n\"\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266f8b9",
   "metadata": {},
   "source": [
    "Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb16014",
   "metadata": {},
   "outputs": [],
   "source": [
    "da3[\"quote.paragraphStartPosition\"] = parstart\n",
    "da3[\"quote.paragraphEndPosition\"] = parend\n",
    "da3[\"quote.paragraphText\"] = par_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a414993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will get the first speaker which is usually probably fine (check the above error output if you want)\n",
    "speaker = par_text.str.lower().str.split(\" person \").str[1].str.split(n=1).str[0].fillna(\"-1\")\n",
    "# different documents have different spacing around the \":\", so it's sometimes left trailing by the above\n",
    "speaker = speaker.str.split(\":\").str[0] # probs would have been more efficient to do this first but whatever\n",
    "speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = speaker.astype(np.int64)\n",
    "da3[\"quote.speaker\"] = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a328936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 valued speaker is inferred to be the learner (because usually it's a code comment that we assume the learner wrote)\n",
    "da3[\"quote.speakerIsLearner\"] = speaker <= 0\n",
    "da3[\"quote.speakerIsLearner\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded3b1c",
   "metadata": {},
   "source": [
    "### Output the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    da3.to_csv(os.path.join(outputdir, annotationsfile))\n",
    "    da3.head(20).to_csv(os.path.join(outputdir, sampleannotationsfile)) # for easy visualization on GitHub\n",
    "    \n",
    "    f = open(os.path.join(outputdir, speakererrorsfile), \"w\")\n",
    "    f.write(err)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50f980",
   "metadata": {},
   "source": [
    "## Consolidate even more even more\n",
    "\n",
    "FIXME BOOKMARK still need to incorporate `Link`s and `Set`s. \n",
    "Also need to take a look at the text files associated with `Code`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(os.path.join(outputdir, annotationsfile), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"quote.text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603834b7-59b7-437c-9aaa-ff20be5be6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
